+----------------------------------------------------------------------------------------------------------------------+
|                                   SAGE-K Python Script (s_index.py) Architecture                                   |
+----------------------------------------------------------------------------------------------------------------------+
|
v
+----------------------------------------------------------------------------------------------------------------------+
| Stage 1: Initialization & Setup                                                                                      |
|----------------------------------------------------------------------------------------------------------------------|
| - Import Libraries (networkx, numpy, spacy, torch, torch_geometric, transformers, sklearn)                           |
| - Define Global Constants:                                                                                           |
|   - STRUCTURAL_WEIGHT, SEMANTIC_WEIGHT, KNOWLEDGE_UPDATE_WEIGHT, DATA_SHARING_WEIGHT                          |
|   - TARGET_NODE_COUNT, TARGET_DATASET_COUNT_FOR_MAX_SCORE                                                        |
| - Load Pre-trained Models:                                                                                           |
|   - biomedlm_tokenizer, biomedlm_model (e.g., "microsoft/BioMedLM-PubMedBERT-base-uncased-abstract-fulltext")     |
|   - nlp (spaCy model, e.g., "en_core_web_md") (Optional, for relation extraction)                                  |
+----------------------------------------------------------------------------------------------------------------------+
|
v
+----------------------------------------------------------------------------------------------------------------------+
| Stage 2: Knowledge Graph Construction & Evolution (within if __name__ == "__main__": block)                        |
|----------------------------------------------------------------------------------------------------------------------|
| - Instantiate KnowledgeGraphBuilder as kg_builder                                                                |
|   - kg_builder.graph: networkx.MultiDiGraph() to store current graph state.                                      |
|   - kg_builder.previous_graph: Stores snapshot before last modification for update metrics.                        |
| - Simulate Data Input (Example Paper/Dataset Dictionaries): paperX_data, datasetY_data                             |
|   - Contains: id, title, abstract/description, citations, researcher_id, year.                         |
| - Iterative Graph Population:                                                                                        |
|   - kg_builder.add_paper(paper_data):                                                                              |
|     -> Calls get_biomedlm_embedding(paper_abstract) -> Stores embedding in node.                                   |
|     -> Adds paper node and citation edges.                                                                           |
|     -> Optionally calls extract_relations_from_abstract_spacy() if nlp model loaded.                           |
|   - kg_builder.add_dataset(dataset_data):                                                                          |
|     -> Calls get_biomedlm_embedding(dataset_description) (if description exists).                                  |
|     -> Adds dataset node.                                                                                            |
|   - kg_builder._update_previous_graph() called before modifications.                                               |
+----------------------------------------------------------------------------------------------------------------------+
|
v
+----------------------------------------------------------------------------------------------------------------------+
| Stage 3: Metric Calculation (Iteratively, as graph evolves)                                                          |
|----------------------------------------------------------------------------------------------------------------------|
| For current current_graph = kg_builder.graph.copy() and previous_graph:                                          |
|                                                                                                                      |
|   1. Calculate Structural Metrics: struc_metrics = calculate_structural_metrics(current_graph)                     |
|      - Input: current_graph                                                                                        |
|      - Computes: Connectivity, Degree Centrality, PageRank, Betweenness, Clustering.                                  |
|      - Output: Dictionary of metric values. avg_structural_score = np.mean(list(struc_metrics.values()))            |
|                                                                                                                      |
|   2. Calculate Semantic Metrics: sem_metrics = calculate_semantic_metrics(current_graph)                           |
|      - Input: current_graph (accesses biomedlm_embedding attribute of nodes).                                   |
|      - Helper: calculate_semantic_similarity_from_embeddings(emb1, emb2) using cosine similarity.                 |
|      - Computes: Average similarity of connected nodes, Knowledge Completeness (vs TARGET_NODE_COUNT).              |
|      - Output: Dictionary. avg_semantic_score = np.mean(list(sem_metrics.values()))                                |
|                                                                                                                      |
|   3. Calculate Knowledge Update Metrics: ku_metrics = calculate_knowledge_update_metrics(current_graph, previous_graph)|
|      - Input: current_graph, previous_graph.                                                                     |
|      - Computes: Integration Rate (new nodes), Centrality Shift, Temporal Consistency (placeholder).                  |
|      - Output: Dictionary. avg_update_score = np.mean(list(ku_metrics.values()))                                   |
|                                                                                                                      |
|   4. Calculate Data Sharing Metrics: ds_info = calculate_data_sharing_metrics(current_graph, researcher_id)        |
|      - Input: current_graph, researcher_id (optional).                                                           |
|      - Counts dataset nodes (type='dataset') associated with researcher or globally.                                  |
|      - Normalizes count against TARGET_DATASET_COUNT_FOR_MAX_SCORE.                                                 |
|      - Output: Dict with data_sharing_score (normalized) and dataset_count.                                     |
+----------------------------------------------------------------------------------------------------------------------+
|
v
+----------------------------------------------------------------------------------------------------------------------+
| Stage 4: S-Index Aggregation & Output                                                                                |
|----------------------------------------------------------------------------------------------------------------------|
| - s_index_value = calculate_s_index(avg_structural_score, avg_semantic_score, avg_update_score, ds_info['data_sharing_score']) |
|   - Applies weights: 0.40*Struct + 0.30*Sem + 0.15*Update + 0.15*DataShare.                                        |
|   - Scales result by 100.                                                                                            |
| - Print to Console: S-Index, component scores, dataset count at each iteration.                                      |
+----------------------------------------------------------------------------------------------------------------------+
|
v
+----------------------------------------------------------------------------------------------------------------------+
| Auxiliary Components (Defined in script, for potential future use with PyTorch)                                      |
|----------------------------------------------------------------------------------------------------------------------|
| - GraphTransformer(nn.Module): Combines Encoder and Decoder.                                                       |
|   - TransformerEncoder(nn.Module): Processes node features (e.g., embeddings).                                    |
|   - GraphAttentionNetwork(nn.Module): Uses torch_geometric.nn.GATConv for graph convolution.                     |
| - Purpose: Advanced graph learning tasks (e.g., prediction, classification) using learned graph representations.     |
| - Requires: Node features and edge index as PyTorch tensors.                                                         |
+----------------------------------------------------------------------------------------------------------------------+
